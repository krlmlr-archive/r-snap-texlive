\documentclass[compose]{exam-n}
\begin{document}

\begin{question}{30} \comment{by Graham Woan}
Distinguish between frequentist and Bayesian definitions of
probability, and explain carefully how parameter estimation is
performed in each regime.\partmarks{10}

A square ccd with $M\times M$ pixels takes a dark frame for
calibration purposes, registering a small number of electrons in
each pixel from thermal noise. The probability of there being $n_i$
electrons in the $i$th pixel follows a Poisson distribution, i.e.
\begin{equation*}
 P(n_i|\lambda) = \exp(-\lambda)\lambda^{n_i}/n_i!,
\end{equation*}
where $\lambda$ is the same constant for all pixels. Show that the
expectation value of  is $\langle n_i \rangle = \lambda$.
\partmarks{5} [You may assume the relation $\sum_0^\infty \frac{x^n}{n!}=\exp(x)$.]

Show similarly that
\begin{equation*}
 \langle n_i(n_i-1) \rangle = \lambda^2.
\end{equation*}
and hence, or otherwise, that the variance of $n_i$ is also
$\lambda$.
\partmarks{5}

The pixels values are summed in columns.  Show that these sums,
$S_j$, will be drawn from a parent probability distribution that is
approximately
\begin{equation*} p(S_j|\lambda)=\frac{1}{\sqrt{2\pi
M\lambda}}\exp\left[-\frac{(S_j-M\lambda)^2}{2M\lambda}\right],
\end{equation*}
clearly stating any theorems you use.
\partmarks{5}

Given the set of $M$ values $\{S_j\}$, and interpreting the above
as a Bayesian likelihood, express the posterior probability for
$\lambda$, justifying any assumptions you make.
\partmarks{5}
\end{question}
\end{document}
